{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "class MCTS:\n",
    "    \"Monte Carlo tree searcher. First rollout the tree then choose a move.\"\n",
    "\n",
    "    def __init__(self, exploration_weight=1):\n",
    "        self.Q = defaultdict(int)  # total reward of each node\n",
    "        self.N = defaultdict(int)  # total visit count for each node\n",
    "        self.children = dict()  # children of each node\n",
    "        self.exploration_weight = exploration_weight\n",
    "\n",
    "    def choose(self, node):\n",
    "        \"Choose the best successor of node. (Choose a move in the game)\"\n",
    "        if node.is_terminal():\n",
    "            raise RuntimeError(f\"choose called on terminal node {node}\")\n",
    "\n",
    "        if node not in self.children:\n",
    "            return node.find_random_child()\n",
    "\n",
    "        def score(n):\n",
    "            if self.N[n] == 0:\n",
    "                return float(\"-inf\")  # avoid unseen moves\n",
    "            return self.Q[n] / self.N[n]  # average reward\n",
    "\n",
    "        return max(self.children[node], key=score)\n",
    "\n",
    "    def do_rollout(self, node):\n",
    "        \"Make the tree one layer better. (Train for one iteration.)\"\n",
    "        path = self._select(node)\n",
    "        leaf = path[-1]\n",
    "        self._expand(leaf)\n",
    "        reward = self._simulate(leaf)\n",
    "        self._backpropagate(path, reward)\n",
    "\n",
    "    def _select(self, node):\n",
    "        \"Find an unexplored descendent of `node`\"\n",
    "        path = []\n",
    "        while True:\n",
    "            path.append(node)\n",
    "            if node not in self.children or not self.children[node]:\n",
    "                # node is either unexplored or terminal\n",
    "                return path\n",
    "            unexplored = self.children[node] - self.children.keys()\n",
    "            if unexplored:\n",
    "                n = unexplored.pop()\n",
    "                path.append(n)\n",
    "                return path\n",
    "            node = self._uct_select(node)  # descend a layer deeper\n",
    "\n",
    "    def _expand(self, node):\n",
    "        \"Update the `children` dict with the children of `node`\"\n",
    "        if node in self.children:\n",
    "            return  # already expanded\n",
    "        self.children[node] = node.find_children()\n",
    "\n",
    "    def _simulate(self, node):\n",
    "        \"Returns the reward for a random simulation (to completion) of `node`\"\n",
    "        #invert_reward = True\n",
    "        reward = 0\n",
    "        while True:\n",
    "            #print(node.to_pretty_string())\n",
    "            if node.is_terminal():\n",
    "                return reward\n",
    "            node = node.find_random_child()\n",
    "            reward = node.get_reward()\n",
    "\n",
    "    def _backpropagate(self, path, reward):\n",
    "        \"Send the reward back up to the ancestors of the leaf\"\n",
    "        for node in reversed(path):\n",
    "            self.N[node] += 1\n",
    "            self.Q[node] += reward\n",
    "            #reward = 1 - reward  # 1 for me is 0 for my enemy, and vice versa\n",
    "\n",
    "    def _uct_select(self, node):\n",
    "        \"Select a child of node, balancing exploration & exploitation\"\n",
    "\n",
    "        # All children of node should already be expanded:\n",
    "        assert all(n in self.children for n in self.children[node])\n",
    "\n",
    "        log_N_vertex = math.log(self.N[node])\n",
    "\n",
    "        def uct(n):\n",
    "            \"Upper confidence bound for trees\"\n",
    "            return self.Q[n] / self.N[n] + self.exploration_weight * math.sqrt(\n",
    "                log_N_vertex / self.N[n]\n",
    "            )\n",
    "\n",
    "        return max(self.children[node], key=uct)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node(ABC):\n",
    "    \"\"\"\n",
    "    A representation of a single board state.\n",
    "    MCTS works by constructing a tree of these Nodes.\n",
    "    Could be e.g. a chess or checkers board state.\n",
    "    \"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def find_children(self):\n",
    "        \"All possible successors of this board state\"\n",
    "        return set()\n",
    "\n",
    "    @abstractmethod\n",
    "    def find_random_child(self):\n",
    "        \"Random successor of this board state (for more efficient simulation)\"\n",
    "        return None\n",
    "\n",
    "    @abstractmethod\n",
    "    def is_terminal(self):\n",
    "        \"Returns True if the node has no children\"\n",
    "        return True\n",
    "\n",
    "#     @abstractmethod\n",
    "#     def reward(self):\n",
    "#         \"Assumes `self` is terminal node. 1=win, 0=loss, .5=tie, etc\"\n",
    "#         return 0\n",
    "\n",
    "#     @abstractmethod\n",
    "#     def __hash__(self):\n",
    "#         \"Nodes must be hashable\"\n",
    "#         return 123456789\n",
    "\n",
    "#     @abstractmethod\n",
    "#     def __eq__(node1, node2):\n",
    "#         \"Nodes must be comparable\"\n",
    "#         return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate random graph of preset size\n",
    "def generate_graph(vertices):\n",
    "    return nx.generators.random_graphs.gnp_random_graph(vertices,\n",
    "                np.random.uniform(0,0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VertexCoverInstance(Node):\n",
    "    def __init__(self, graph, cover = [], reward = 0):\n",
    "        self.graph = graph\n",
    "        self.cover = cover\n",
    "        self.reward = reward\n",
    "        \n",
    "    def find_children(self):\n",
    "        possiblemoves = {}\n",
    "        if self.is_terminal():  # If the game is finished then no moves can be made\n",
    "            return possiblemoves\n",
    "        for i in list(self.graph.nodes):\n",
    "            H = self.graph.copy()\n",
    "            if H.degree[i]:\n",
    "                step_reward = -1\n",
    "                H.remove_node(i)\n",
    "                possiblemoves.append(VertexCoverInstance(H, self.cover+[i], self.reward+step_reward))\n",
    "        return possiblemoves\n",
    "\n",
    "    def find_random_child(self):\n",
    "        if self.is_terminal():\n",
    "            return None  # If the game is finished then no moves can be made\n",
    "        temp = self.find_children()\n",
    "        return random.sample(set(temp),1)[0]\n",
    "\n",
    "#     def reward(board):\n",
    "#         if not board.terminal:\n",
    "#             raise RuntimeError(f\"reward called on nonterminal board {board}\")\n",
    "#         return self.reward #reward comes upon reaching terminal state\n",
    "\n",
    "    def is_terminal(self):\n",
    "        return nx.classes.function.is_empty(self.graph)\n",
    "\n",
    "    def to_pretty_string(self):\n",
    "        return str(list(self.graph.nodes()))\n",
    "    \n",
    "    def get_cover(self):\n",
    "        return self.cover\n",
    "    \n",
    "    def get_reward(self):\n",
    "        return self.reward\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_game(G, display = True):\n",
    "    tree = MCTS()\n",
    "    board = VertexCoverInstance(G)\n",
    "    #print(board.to_pretty_string())\n",
    "    moves = 0\n",
    "    while True:\n",
    "        if board.is_terminal():\n",
    "            break\n",
    "        #80 rollouts per turn\n",
    "        for _ in range(80):\n",
    "            tree.do_rollout(board)\n",
    "        board = tree.choose(board)\n",
    "        #print(board.to_pretty_string())\n",
    "        moves = moves+1\n",
    "        if board.is_terminal():\n",
    "            break\n",
    "            \n",
    "    vc = board.get_cover()\n",
    "    if display:\n",
    "        print(\"\\n\\nMCTS APPROX\\n\")\n",
    "        print(vc)\n",
    "        color_map = []\n",
    "        for node in G:\n",
    "            if node in vc:\n",
    "                color_map.append('red')\n",
    "            else: \n",
    "                color_map.append('blue')  \n",
    "        plt.figure(1)\n",
    "        nx.draw(G, node_color=color_map, with_labels=True)\n",
    "        \n",
    "    return vc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx.algorithms import approximation as appx\n",
    "import itertools\n",
    "\n",
    "def show_optimal_vc(G, display=True):\n",
    "    #opt = list(appx.vertex_cover.min_weighted_vertex_cover(G))\n",
    "    def findsubsets(s): \n",
    "        lists =[list(itertools.combinations(s, n)) for n in range(len(s))]\n",
    "        return list(itertools.chain.from_iterable(lists))\n",
    "    \n",
    "    powerset = findsubsets(list(G.nodes()))    \n",
    "    for s in powerset:\n",
    "        H = G.copy()\n",
    "        H.remove_nodes_from(s)\n",
    "        if nx.classes.function.is_empty(H):\n",
    "            opt = list(s)\n",
    "            break\n",
    "    if display:\n",
    "        print(\"\\n\\nOPTIMAL\\n\")\n",
    "        print(opt)\n",
    "        color_map = []\n",
    "        for node in G:\n",
    "            if node in opt:\n",
    "                color_map.append('orange')\n",
    "            else: \n",
    "                color_map.append('green')\n",
    "        plt.figure(2)\n",
    "        nx.draw(G, node_color=color_map, with_labels=True)\n",
    "        \n",
    "    return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'exists' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-124-43af5505222a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mvc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplay_game\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshow_optimal_vc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-122-962f7bec6345>\u001b[0m in \u001b[0;36mplay_game\u001b[0;34m(G, display)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m#80 rollouts per turn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_rollout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mboard\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m#print(board.to_pretty_string())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-109-94809fa0687e>\u001b[0m in \u001b[0;36mdo_rollout\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mleaf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleaf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_simulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleaf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backpropagate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-109-94809fa0687e>\u001b[0m in \u001b[0;36m_expand\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mreturn\u001b[0m  \u001b[0;31m# already expanded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_children\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_simulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-121-a01f0862ad20>\u001b[0m in \u001b[0;36mfind_children\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mpossiblemoves\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mVertexCoverInstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcover\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstep_reward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0;31m#possiblemoves.append(VertexCoverInstance(H, self.cover+[i], self.reward+step_reward))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpossiblemoves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'exists' referenced before assignment"
     ]
    }
   ],
   "source": [
    "G = generate_graph(10)\n",
    "vc = play_game(G)\n",
    "print()\n",
    "opt = show_optimal_vc(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "NUM_SIMS = 100\n",
    "\n",
    "def sim_test_approx(simulations):\n",
    "    count_success = 0\n",
    "    for x in range(simulations):\n",
    "        A = generate_graph(10)\n",
    "        vc = play_game(A, display=False)\n",
    "        opt = show_optimal_vc(A, display=False)\n",
    "        if len(vc)<=len(opt)*1.1:\n",
    "            count_success=count_success+1\n",
    "    print(count_success)\n",
    "    return count_success\n",
    "\n",
    "count = sim_test_approx(NUM_SIMS)\n",
    "plot_arr = [count,NUM_SIMS-count]\n",
    "plt.figure(3)\n",
    "plt.pie(plot_arr, colors = ['lightcoral','lightskyblue'], labels = ['good approx', 'bad approx'],autopct='%1.2f%%')\n",
    "plt.title('Percentage of Good MCTS Approximations (Min Vertex Cover)')\n",
    "plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCTS_AZ:\n",
    "    \"Monte Carlo tree searcher with GNN. First rollout the tree then choose a move.\"\n",
    "\n",
    "    def __init__(self, net, exploration_weight=1):\n",
    "        self.Q = defaultdict(int)  # total reward of each node\n",
    "        self.N = defaultdict(int)  # total visit count for each node\n",
    "        self.children = dict()  # children of each node\n",
    "        self.priors = dict() # prior probability of visiting each child of a given node\n",
    "        self.exploration_weight = exploration_weight\n",
    "        self.net = net\n",
    "\n",
    "    def choose(self, node):\n",
    "        \"Choose the best successor of node. (Choose a move in the game)\"\n",
    "        if node.is_terminal():\n",
    "            raise RuntimeError(f\"choose called on terminal node {node}\")\n",
    "\n",
    "        if node not in self.children:\n",
    "            return node.find_random_child()\n",
    "\n",
    "        def score(n):\n",
    "            if self.N[n] == 0:\n",
    "                return float(\"-inf\")  # avoid unseen moves\n",
    "            return self.Q[n] / self.N[n]  # average reward\n",
    "\n",
    "        return max(self.children[node], key=score)\n",
    "    \n",
    "    def choose_by_policy(self, node):\n",
    "        \"Choose a successor of node according to policy\"\n",
    "        if node.is_terminal():\n",
    "            raise RuntimeError(f\"choose called on terminal node {node}\")\n",
    "            \n",
    "        if node not in self.children:\n",
    "            return node.find_random_child()\n",
    "        \n",
    "        policy = list(map(lambda n: self.N[n]/(self.N[node]-1), self.children[node]))\n",
    "        action = np.random.choice(len(policy), 1, p=policy)[0]\n",
    "        successor = self.children[node][action]\n",
    "\n",
    "        return successor,policy\n",
    "\n",
    "    def do_rollout(self, node):\n",
    "        \"Make the tree one layer better. (Train for one iteration.)\"\n",
    "        path = self._select(node)\n",
    "        leaf = path[-1]\n",
    "        self._expand(leaf)\n",
    "        reward = self._simulate(leaf)\n",
    "        self._backpropagate(path, reward)\n",
    "\n",
    "    def _select(self, node):\n",
    "        \"Find an unexplored descendent of `node`\"\n",
    "        path = []\n",
    "        while True:\n",
    "            path.append(node)\n",
    "            if node not in self.children or not self.children[node]:\n",
    "                # node is either unexplored or terminal\n",
    "                return path\n",
    "            for child in self.children[node]:\n",
    "                if child not in self.children:\n",
    "                    path.append(child)\n",
    "                    return path\n",
    "            node = self._uct_select(node)  # descend a layer deeper\n",
    "\n",
    "    def _expand(self, node):\n",
    "        \"Update the `children` dict with the children of `node`\"\n",
    "        if node in self.children:\n",
    "            return  # already expanded\n",
    "        children = node.find_children()\n",
    "        self.children[node] = children\n",
    "        if children:\n",
    "            self.priors[node] = self.net.predict(node)\n",
    "\n",
    "    def _simulate(self, node):\n",
    "        \"Returns the reward for a random simulation (to completion) of `node`\"\n",
    "        reward = 0\n",
    "        while True:\n",
    "            reward += node.get_reward()\n",
    "            if node.is_terminal():\n",
    "                return reward\n",
    "            node = node.find_random_child()\n",
    "\n",
    "    def _backpropagate(self, path, reward):\n",
    "        \"Send the reward back up to the ancestors of the leaf\"\n",
    "        for node in reversed(path):\n",
    "            self.N[node] += 1\n",
    "            self.Q[node] += reward\n",
    "\n",
    "    def _uct_select(self, node):\n",
    "        \"Select a child of node, balancing exploration & exploitation\"\n",
    "\n",
    "        # All children of node should already be expanded:\n",
    "        assert all(n in self.children for n in self.children[node])\n",
    "\n",
    "        log_N_vertex = math.log(self.N[node])\n",
    "\n",
    "        def uct(n):\n",
    "            \"Upper confidence bound for trees\"\n",
    "            i,n = n # expand from enumerate tuple\n",
    "#             return self.Q[n] / self.N[n] + self.exploration_weight * self.priors[node][i] * math.sqrt(\n",
    "#                 log_N_vertex / self.N[n]\n",
    "#             )\n",
    "            return self.Q[n] / self.N[n] + self.exploration_weight * math.sqrt(\n",
    "                 log_N_vertex / self.N[n]\n",
    "            )\n",
    "\n",
    "        return max(enumerate(self.children[node]), key=uct)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_game_AZ(G, net,num_rollouts=80, display = True):\n",
    "    tree = MCTS_AZ(net)\n",
    "    board = VertexCoverInstance(G)\n",
    "    while True:\n",
    "        if board.is_terminal():\n",
    "            break\n",
    "        for _ in range(num_rollouts):\n",
    "            tree.do_rollout(board)\n",
    "        board = tree.choose(board)\n",
    "            \n",
    "    vc = board.get_cover()\n",
    "    if display:\n",
    "        print(\"\\n\\nMCTS APPROX\\n\")\n",
    "        print(vc)\n",
    "        color_map = []\n",
    "        for node in G:\n",
    "            if node in vc:\n",
    "                color_map.append('red')\n",
    "            else: \n",
    "                color_map.append('blue')  \n",
    "        plt.figure(1)\n",
    "        nx.draw(G, node_color=color_map, with_labels=True)\n",
    "        \n",
    "    return vc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def self_play(G, net, num_rollouts=80):\n",
    "    tree = MCTS_AZ(net)\n",
    "    board = VertexCoverInstance(G)\n",
    "    data = []\n",
    "    while True:\n",
    "        if board.is_terminal():\n",
    "            break\n",
    "        for _ in range(num_rollouts):\n",
    "            tree.do_rollout(board)\n",
    "        new_board, policy = tree.choose_by_policy(board)\n",
    "        record = from_networkx(board.graph)\n",
    "        record.y = torch.tensor(policy).reshape(1,-1)\n",
    "        data.append(record)\n",
    "        board = new_board \n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.utils import from_networkx\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GCNConv(1, 16)\n",
    "        self.conv2 = GCNConv(16, 16)\n",
    "        self.conv_prob = GCNConv(16, 1)\n",
    "\n",
    "    # expects a torch_geometric Data object\n",
    "    def forward(self, data):\n",
    "        num_nodes = data.num_nodes\n",
    "        x = torch.tensor([[1.0] for _ in range(num_nodes)])\n",
    "        edge_index = data.edge_index\n",
    "        x = self.conv1(x ,edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        edge_index = data.edge_index\n",
    "        x = self.conv2(x ,edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        probs = self.conv_prob(x, edge_index).reshape(-1,num_nodes)\n",
    "        return F.softmax(probs,dim=1)\n",
    "    \n",
    "    def predict(self, instance):\n",
    "        data = from_networkx(instance.graph)\n",
    "        return self.forward(data).flatten().tolist()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "Getting self-play records\n",
      "  Generated game 20\n",
      "  Generated game 40\n",
      "  Generated game 60\n",
      "  Generated game 80\n",
      "  Generated game 100\n",
      "Training\n",
      "Epoch 0 loss: 0.574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:498: UserWarning: Using a target size (torch.Size([13, 10])) that is different to the input size (torch.Size([1, 130])) is deprecated. Please ensure they have the same size.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 loss: 0.569\n",
      "Epoch 20 loss: 0.569\n",
      "Epoch 30 loss: 0.567\n",
      "Epoch 40 loss: 0.569\n",
      "Epoch 50 loss: 0.567\n",
      "Epoch 60 loss: 0.569\n",
      "Epoch 70 loss: 0.568\n",
      "Epoch 80 loss: 0.567\n",
      "Epoch 90 loss: 0.568\n",
      "Evaluating\n",
      "Score: 0.700\n",
      "Iteration 1\n",
      "Getting self-play records\n",
      "  Generated game 20\n",
      "  Generated game 40\n",
      "  Generated game 60\n",
      "  Generated game 80\n",
      "  Generated game 100\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:498: UserWarning: Using a target size (torch.Size([29, 10])) that is different to the input size (torch.Size([1, 290])) is deprecated. Please ensure they have the same size.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss: 0.571\n",
      "Epoch 10 loss: 0.571\n",
      "Epoch 20 loss: 0.571\n",
      "Epoch 30 loss: 0.572\n",
      "Epoch 40 loss: 0.571\n",
      "Epoch 50 loss: 0.572\n",
      "Epoch 60 loss: 0.570\n",
      "Epoch 70 loss: 0.571\n",
      "Epoch 80 loss: 0.571\n",
      "Epoch 90 loss: 0.572\n",
      "Evaluating\n",
      "Score: 0.620\n",
      "Iteration 2\n",
      "Getting self-play records\n",
      "  Generated game 20\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-d66d3afd9a50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_SELF_GAMES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIN_GRAPH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mrecords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_play\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m20\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m19\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"  Generated game %d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-74-47723ebf6dcc>\u001b[0m in \u001b[0;36mself_play\u001b[0;34m(G, net, num_rollouts)\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_rollouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_rollout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mnew_board\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoose_by_policy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mrecord\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrom_networkx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-72-624353b58d65>\u001b[0m in \u001b[0;36mdo_rollout\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mleaf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleaf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_simulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleaf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backpropagate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-72-624353b58d65>\u001b[0m in \u001b[0;36m_simulate\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_terminal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_random_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_backpropagate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-77-d68f2aa53465>\u001b[0m in \u001b[0;36mfind_random_child\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_terminal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# If the game is finished then no moves can be made\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_children\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-77-d68f2aa53465>\u001b[0m in \u001b[0;36mfind_children\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mpossiblemoves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0;31m#if H.degree[i]:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/networkx/classes/graph.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(self, as_view)\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_nodes_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1514\u001b[0m         G.add_edges_from((u, v, datadict.copy())\n\u001b[0;32m-> 1515\u001b[0;31m                          \u001b[0;32mfor\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbrs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1516\u001b[0m                          for v, datadict in nbrs.items())\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/networkx/classes/graph.py\u001b[0m in \u001b[0;36madd_edges_from\u001b[0;34m(self, ebunch_to_add, **attr)\u001b[0m\n\u001b[1;32m    930\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_edges_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'WN2898'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \"\"\"\n\u001b[0;32m--> 932\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mebunch_to_add\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    933\u001b[0m             \u001b[0mne\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mne\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/networkx/classes/graph.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1514\u001b[0m         G.add_edges_from((u, v, datadict.copy())\n\u001b[1;32m   1515\u001b[0m                          \u001b[0;32mfor\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbrs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1516\u001b[0;31m                          for v, datadict in nbrs.items())\n\u001b[0m\u001b[1;32m   1517\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "TRAIN_GRAPH_SIZE = 10\n",
    "TEST_GRAPH_SIZE = 10\n",
    "\n",
    "NUM_ITERS = 5\n",
    "NUM_SELF_GAMES = 100\n",
    "NUM_EPOCHS = 100\n",
    "NUM_EVAL_SIMS = 50\n",
    "\n",
    "scores = []\n",
    "\n",
    "net = Net()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr = 0.01)\n",
    "criterion=torch.nn.BCELoss()\n",
    "\n",
    "for i in range(NUM_ITERS):\n",
    "    print('Iteration %d' % (i))\n",
    "    \n",
    "    # get self-play records\n",
    "    print(\"Getting self-play records\")\n",
    "    records = []\n",
    "    for i in range(NUM_SELF_GAMES):\n",
    "        A = generate_graph(TRAIN_GRAPH_SIZE)\n",
    "        records.extend(self_play(A, net))\n",
    "        if i % 20 == 19:\n",
    "            print(\"  Generated game %d\" % (i+1))\n",
    "    \n",
    "    # training\n",
    "    print(\"Training\")\n",
    "    data_loader = DataLoader(records, batch_size=32, shuffle=True)\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        total_loss = 0\n",
    "        num_batches = 0\n",
    "        for batch in data_loader:\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(batch)\n",
    "            loss = criterion(outputs, batch.y)\n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        if epoch % 10 == 0:\n",
    "            print('Epoch %d loss: %.3f' %\n",
    "                  (epoch, total_loss / num_batches))\n",
    "    \n",
    "    # evaluate on larger test graphs\n",
    "    print(\"Evaluating\")\n",
    "    count_success = 0\n",
    "    for x in range(NUM_EVAL_SIMS):\n",
    "        A = generate_graph(TEST_GRAPH_SIZE)\n",
    "        vc = play_game_AZ(A, net,display=False)\n",
    "        opt = show_optimal_vc(A, display=False)\n",
    "        if len(vc)<=len(opt)*1.1:\n",
    "            count_success=count_success+1\n",
    "    print('Score: %.3f' % (count_success / NUM_EVAL_SIMS))\n",
    "    scores.append(count_success / NUM_EVAL_SIMS)\n",
    "    \n",
    "\n",
    "plt.plot(scores)\n",
    "plt.ylabel('Performance')\n",
    "plt.xlabel('Self Play / Training Iterations')\n",
    "plt.title('Percentage of Good AlphaMinVertex Approximations during Training')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
