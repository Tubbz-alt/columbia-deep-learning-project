{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-355-723a60b81a3e>, line 72)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-355-723a60b81a3e>\"\u001b[0;36m, line \u001b[0;32m72\u001b[0m\n\u001b[0;31m    def _simulate(self, node):\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class MCTS:\n",
    "    \"Monte Carlo tree searcher. First rollout the tree then choose a move.\"\n",
    "\n",
    "    def __init__(self, net, exploration_weight=1.5):\n",
    "        self.Q = defaultdict(int)  # total reward of each node\n",
    "        self.N = defaultdict(int)  # total visit count for each node\n",
    "        self.children = dict()  # children of each node\n",
    "        self.priors = dict() # prior probability of visiting each child of a given node\n",
    "        self.exploration_weight = exploration_weight\n",
    "        self.net = net\n",
    "\n",
    "    def choose(self, node):\n",
    "        \"Choose the best successor of node. (Choose a move in the game)\"\n",
    "        if node.is_terminal():\n",
    "            raise RuntimeError(f\"choose called on terminal node {node}\")\n",
    "\n",
    "        if node not in self.children:\n",
    "            return node.find_random_child()\n",
    "\n",
    "        def score(n):\n",
    "            if self.N[n] == 0:\n",
    "                return float(\"-inf\")  # avoid unseen moves\n",
    "            return self.Q[n] / self.N[n]  # average reward\n",
    "\n",
    "        return max(self.children[node], key=score)\n",
    "    \n",
    "    def choose_by_policy(self, node):\n",
    "        \"Choose a successor of node according to policy\"\n",
    "        if node.is_terminal():\n",
    "            raise RuntimeError(f\"choose called on terminal node {node}\")\n",
    "            \n",
    "        if node not in self.children:\n",
    "            return node.find_random_child()\n",
    "        \n",
    "        policy = list(map(lambda n: self.N[n]/(self.N[node]-1), self.children[node]))\n",
    "        action = np.random.choice(len(policy), 1, p=policy)[0]\n",
    "        successor = self.children[node][action]\n",
    "\n",
    "        return successor,policy\n",
    "\n",
    "    def do_rollout(self, node):\n",
    "        \"Make the tree one layer better. (Train for one iteration.)\"\n",
    "        path = self._select(node)\n",
    "        leaf = path[-1]\n",
    "        self._expand(leaf)\n",
    "        reward = self._simulate(leaf)\n",
    "        self._backpropagate(path, reward)\n",
    "\n",
    "    def _select(self, node):\n",
    "        \"Find an unexplored descendent of `node`\"\n",
    "        path = []\n",
    "        while True:\n",
    "            path.append(node)\n",
    "            if node not in self.children or not self.children[node]:\n",
    "                # node is either unexplored or terminal\n",
    "                return path\n",
    "            for child in self.children[node]:\n",
    "                if child not in self.children:\n",
    "                    path.append(child)\n",
    "                    return path\n",
    "            node = self._uct_select(node)  # descend a layer deeper\n",
    "\n",
    "    def _expand(self, node):\n",
    "        \"Update the `children` dict with the children of `node`\"\n",
    "        if node in self.children:\n",
    "            return  # already expanded\n",
    "        children = node.find_children()\n",
    "        self.children[node] = children\n",
    "        if children:\n",
    "            self.priors[node] = list(map(lambda x: x*len(children), self.net.predict(node))\n",
    "\n",
    "    def _simulate(self, node):\n",
    "        \"Returns the reward for a random simulation (to completion) of `node`\"\n",
    "        reward = 0\n",
    "        while True:\n",
    "            reward += node.get_reward()\n",
    "            if node.is_terminal():\n",
    "                return reward\n",
    "            node = node.find_random_child()\n",
    "\n",
    "    def _backpropagate(self, path, reward):\n",
    "        \"Send the reward back up to the ancestors of the leaf\"\n",
    "        for node in reversed(path):\n",
    "            self.N[node] += 1\n",
    "            self.Q[node] += reward\n",
    "\n",
    "    def _uct_select(self, node):\n",
    "        \"Select a child of node, balancing exploration & exploitation\"\n",
    "\n",
    "        # All children of node should already be expanded:\n",
    "        assert all(n in self.children for n in self.children[node])\n",
    "\n",
    "        log_N_vertex = math.log(self.N[node])\n",
    "\n",
    "        def uct(n):\n",
    "            \"Upper confidence bound for trees\"\n",
    "            i,n = n # expand from enumerate tuple\n",
    "            return self.Q[n] / self.N[n] + self.exploration_weight * self.priors[node][i] * math.sqrt(\n",
    "                log_N_vertex / self.N[n]\n",
    "            )\n",
    "\n",
    "        return max(enumerate(self.children[node]), key=uct)[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node(ABC):\n",
    "    \"\"\"\n",
    "    A representation of a single board state.\n",
    "    MCTS works by constructing a tree of these Nodes.\n",
    "    Could be e.g. a chess or checkers board state.\n",
    "    \"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def find_children(self):\n",
    "        \"All possible successors of this board state\"\n",
    "        return set()\n",
    "\n",
    "    @abstractmethod\n",
    "    def find_random_child(self):\n",
    "        \"Random successor of this board state (for more efficient simulation)\"\n",
    "        return None\n",
    "\n",
    "    @abstractmethod\n",
    "    def is_terminal(self):\n",
    "        \"Returns True if the node has no children\"\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate random graph of preset size\n",
    "def generate_graph(vertices):\n",
    "    return nx.generators.random_graphs.gnp_random_graph(vertices,\n",
    "                np.random.uniform(0,0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VertexCoverInstance(Node):\n",
    "    def __init__(self, graph, cover = []):\n",
    "        self.graph = graph\n",
    "        self.cover = cover\n",
    "        \n",
    "    def find_children(self):\n",
    "        possiblemoves = []\n",
    "        if self.is_terminal():  # If the game is finished then no moves can be made\n",
    "            return set(possiblemoves)\n",
    "        for i in list(self.graph.nodes):\n",
    "            H = self.graph.copy()\n",
    "            neigh = H.neighbors(i)\n",
    "            H.remove_node(i)\n",
    "            H.add_node(i)\n",
    "            possiblemoves.append(VertexCoverInstance(H, self.cover+[i]))\n",
    "        return possiblemoves\n",
    "\n",
    "    def find_random_child(self):\n",
    "        if self.is_terminal():\n",
    "            return None  # If the game is finished then no moves can be made\n",
    "        temp = self.find_children()\n",
    "        return random.sample(temp,1)[0]\n",
    "\n",
    "    def is_terminal(self):\n",
    "        return nx.classes.function.is_empty(self.graph)\n",
    "\n",
    "    def to_pretty_string(self):\n",
    "        return str(list(self.graph.nodes()))\n",
    "    \n",
    "    def get_cover(self):\n",
    "        return self.cover\n",
    "    \n",
    "    def get_reward(self):\n",
    "        if self.is_terminal():\n",
    "             return 0\n",
    "        return -1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_game(G, net, num_rollouts=80, display = True):\n",
    "    tree = MCTS(net)\n",
    "    board = VertexCoverInstance(G)\n",
    "    while True:\n",
    "        if board.is_terminal():\n",
    "            break\n",
    "        for _ in range(num_rollouts):\n",
    "            tree.do_rollout(board)\n",
    "        board = tree.choose(board)\n",
    "            \n",
    "    vc = board.get_cover()\n",
    "    if display:\n",
    "        print(\"\\n\\nMCTS APPROX\\n\")\n",
    "        print(vc)\n",
    "        color_map = []\n",
    "        for node in G:\n",
    "            if node in vc:\n",
    "                color_map.append('red')\n",
    "            else: \n",
    "                color_map.append('blue')  \n",
    "        plt.figure(1)\n",
    "        nx.draw(G, node_color=color_map, with_labels=True)\n",
    "        \n",
    "    return vc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "def self_play(G, net, num_rollouts=80):\n",
    "    tree = MCTS(net)\n",
    "    board = VertexCoverInstance(G)\n",
    "    data = []\n",
    "    while True:\n",
    "        if board.is_terminal():\n",
    "            break\n",
    "        for _ in range(num_rollouts):\n",
    "            tree.do_rollout(board)\n",
    "        new_board, policy = tree.choose_by_policy(board)\n",
    "        record = from_networkx(board.graph)\n",
    "        record.y = torch.tensor(policy).reshape(1,-1)\n",
    "        data.append(record)\n",
    "        board = new_board \n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx.algorithms import approximation as appx\n",
    "import itertools\n",
    "\n",
    "def show_optimal_vc(G, display=True):\n",
    "    def findsubsets(s): \n",
    "        lists =[list(itertools.combinations(s, n)) for n in range(len(s))]\n",
    "        return list(itertools.chain.from_iterable(lists))\n",
    "    \n",
    "    powerset = findsubsets(list(G.nodes()))    \n",
    "    for s in powerset:\n",
    "        H = G.copy()\n",
    "        H.remove_nodes_from(s)\n",
    "        if nx.classes.function.is_empty(H):\n",
    "            opt = list(s)\n",
    "            break\n",
    "    if display:\n",
    "        print(\"\\n\\nOPTIMAL\\n\")\n",
    "        print(opt)\n",
    "        color_map = []\n",
    "        for node in G:\n",
    "            if node in opt:\n",
    "                color_map.append('orange')\n",
    "            else: \n",
    "                color_map.append('green')\n",
    "        plt.figure(2)\n",
    "        nx.draw(G, node_color=color_map, with_labels=True)\n",
    "        \n",
    "    return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.utils import from_networkx\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GCNConv(1, 16)\n",
    "        self.conv2 = GCNConv(16, 16)\n",
    "        self.conv3 = GCNConv(16, 16)\n",
    "        self.conv4 = GCNConv(16, 16)\n",
    "        self.conv_prob = GCNConv(16, 1)\n",
    "\n",
    "    # expects a torch_geometric Data object\n",
    "    def forward(self, data):\n",
    "        num_nodes = data.num_nodes\n",
    "        x = torch.tensor([[1.0] for _ in range(num_nodes)])\n",
    "        edge_index = data.edge_index\n",
    "        x = self.conv1(x ,edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        edge_index = data.edge_index\n",
    "        x = self.conv2(x ,edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv3(x ,edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv4(x ,edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        probs = self.conv_prob(x, edge_index).reshape(-1,num_nodes)\n",
    "        return F.softmax(probs,dim=1)\n",
    "    \n",
    "    def predict(self, instance):\n",
    "        data = from_networkx(instance.graph)\n",
    "        return self.forward(data).flatten().tolist()\n",
    "        \n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\n",
      "Getting self-play records\n",
      "  Generated game 10\n",
      "  Generated game 20\n",
      "  Generated game 30\n",
      "  Generated game 40\n",
      "  Generated game 50\n",
      "Training\n",
      "Epoch 10 loss: 0.508\n",
      "Epoch 20 loss: 0.503\n",
      "Epoch 30 loss: 0.499\n",
      "Epoch 40 loss: 0.499\n",
      "Epoch 50 loss: 0.498\n",
      "Epoch 60 loss: 0.496\n",
      "Epoch 70 loss: 0.496\n",
      "Epoch 80 loss: 0.494\n",
      "Epoch 90 loss: 0.497\n",
      "Epoch 100 loss: 0.496\n",
      "Evaluating\n",
      "Score: 0.640\n",
      "Iteration 2\n",
      "Getting self-play records\n",
      "  Generated game 10\n",
      "  Generated game 20\n",
      "  Generated game 30\n",
      "  Generated game 40\n",
      "  Generated game 50\n",
      "Training\n",
      "Epoch 10 loss: 0.494\n",
      "Epoch 20 loss: 0.489\n",
      "Epoch 30 loss: 0.492\n",
      "Epoch 40 loss: 0.489\n",
      "Epoch 50 loss: 0.491\n",
      "Epoch 60 loss: 0.490\n",
      "Epoch 70 loss: 0.491\n",
      "Epoch 80 loss: 0.495\n",
      "Epoch 90 loss: 0.490\n",
      "Epoch 100 loss: 0.491\n",
      "Evaluating\n",
      "Score: 0.600\n",
      "Iteration 3\n",
      "Getting self-play records\n",
      "  Generated game 10\n",
      "  Generated game 20\n",
      "  Generated game 30\n",
      "  Generated game 40\n",
      "  Generated game 50\n",
      "Training\n",
      "Epoch 10 loss: 0.489\n",
      "Epoch 20 loss: 0.488\n",
      "Epoch 30 loss: 0.486\n",
      "Epoch 40 loss: 0.486\n",
      "Epoch 50 loss: 0.486\n",
      "Epoch 60 loss: 0.487\n",
      "Epoch 70 loss: 0.485\n",
      "Epoch 80 loss: 0.485\n",
      "Epoch 90 loss: 0.487\n",
      "Epoch 100 loss: 0.488\n",
      "Evaluating\n",
      "Score: 0.520\n",
      "Iteration 4\n",
      "Getting self-play records\n",
      "  Generated game 10\n",
      "  Generated game 20\n",
      "  Generated game 30\n",
      "  Generated game 40\n",
      "  Generated game 50\n",
      "Training\n",
      "Epoch 10 loss: 0.485\n",
      "Epoch 20 loss: 0.487\n",
      "Epoch 30 loss: 0.485\n",
      "Epoch 40 loss: 0.484\n",
      "Epoch 50 loss: 0.483\n",
      "Epoch 60 loss: 0.484\n",
      "Epoch 70 loss: 0.484\n",
      "Epoch 80 loss: 0.483\n",
      "Epoch 90 loss: 0.483\n",
      "Epoch 100 loss: 0.486\n",
      "Evaluating\n",
      "Score: 0.640\n",
      "Iteration 5\n",
      "Getting self-play records\n",
      "  Generated game 10\n",
      "  Generated game 20\n",
      "  Generated game 30\n",
      "  Generated game 40\n",
      "  Generated game 50\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/torch/nn/modules/loss.py:498: UserWarning: Using a target size (torch.Size([11, 10])) that is different to the input size (torch.Size([1, 110])) is deprecated. Please ensure they have the same size.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 loss: 0.489\n",
      "Epoch 20 loss: 0.489\n",
      "Epoch 30 loss: 0.489\n",
      "Epoch 40 loss: 0.489\n",
      "Epoch 50 loss: 0.490\n",
      "Epoch 60 loss: 0.489\n",
      "Epoch 70 loss: 0.489\n",
      "Epoch 80 loss: 0.489\n",
      "Epoch 90 loss: 0.493\n",
      "Epoch 100 loss: 0.493\n",
      "Evaluating\n",
      "Score: 0.360\n",
      "Iteration 6\n",
      "Getting self-play records\n",
      "  Generated game 10\n",
      "  Generated game 20\n",
      "  Generated game 30\n",
      "  Generated game 40\n",
      "  Generated game 50\n",
      "Training\n",
      "Epoch 10 loss: 0.488\n",
      "Epoch 20 loss: 0.492\n",
      "Epoch 30 loss: 0.491\n",
      "Epoch 40 loss: 0.490\n",
      "Epoch 50 loss: 0.492\n",
      "Epoch 60 loss: 0.491\n",
      "Epoch 70 loss: 0.489\n",
      "Epoch 80 loss: 0.487\n",
      "Epoch 90 loss: 0.492\n",
      "Epoch 100 loss: 0.490\n",
      "Evaluating\n",
      "Score: 0.560\n",
      "Iteration 7\n",
      "Getting self-play records\n",
      "  Generated game 10\n",
      "  Generated game 20\n",
      "  Generated game 30\n",
      "  Generated game 40\n",
      "  Generated game 50\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/torch/nn/modules/loss.py:498: UserWarning: Using a target size (torch.Size([4, 10])) that is different to the input size (torch.Size([1, 40])) is deprecated. Please ensure they have the same size.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 loss: 0.482\n",
      "Epoch 20 loss: 0.486\n",
      "Epoch 30 loss: 0.483\n",
      "Epoch 40 loss: 0.479\n",
      "Epoch 50 loss: 0.480\n",
      "Epoch 60 loss: 0.484\n",
      "Epoch 70 loss: 0.486\n",
      "Epoch 80 loss: 0.481\n",
      "Epoch 90 loss: 0.483\n",
      "Epoch 100 loss: 0.483\n",
      "Evaluating\n",
      "Score: 0.680\n",
      "Iteration 8\n",
      "Getting self-play records\n",
      "  Generated game 10\n",
      "  Generated game 20\n",
      "  Generated game 30\n",
      "  Generated game 40\n",
      "  Generated game 50\n",
      "Training\n",
      "Epoch 10 loss: 0.489\n",
      "Epoch 20 loss: 0.486\n",
      "Epoch 30 loss: 0.487\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "TRAIN_GRAPH_SIZE = 10\n",
    "TEST_GRAPH_SIZE = 10\n",
    "\n",
    "NUM_ITERS = 20\n",
    "NUM_SELF_GAMES = 50\n",
    "NUM_EPOCHS = 100\n",
    "NUM_EVAL_SIMS = 25\n",
    "\n",
    "scores = []\n",
    "\n",
    "net = Net()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr = 0.001)\n",
    "criterion=torch.nn.BCELoss()\n",
    "\n",
    "for i in range(NUM_ITERS):\n",
    "    print('Iteration %d' % (i+1))\n",
    "    \n",
    "    # get self-play records\n",
    "    print(\"Getting self-play records\")\n",
    "    records = []\n",
    "    for i in range(NUM_SELF_GAMES):\n",
    "        A = generate_graph(TRAIN_GRAPH_SIZE)\n",
    "        records.extend(self_play(A, net))\n",
    "        if i % 10 == 9:\n",
    "            print(\"  Generated game %d\" % (i+1))\n",
    "    \n",
    "    # training\n",
    "    print(\"Training\")\n",
    "    data_loader = DataLoader(records, batch_size=16, shuffle=True)\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        total_loss = 0\n",
    "        num_batches = 0\n",
    "        for batch in data_loader:\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(batch)\n",
    "            loss = criterion(outputs, batch.y)\n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        if epoch % 10 == 9:\n",
    "            print('  Epoch %d loss: %.3f' %\n",
    "                  (epoch+1, total_loss / num_batches))\n",
    "    \n",
    "    # evaluate on larger test graphs\n",
    "    print(\"Evaluating\")\n",
    "    count_success = 0\n",
    "    for x in range(NUM_EVAL_SIMS):\n",
    "        A = generate_graph(TEST_GRAPH_SIZE)\n",
    "        vc = play_game(A, net, display=False)\n",
    "        opt = show_optimal_vc(A, display=False)\n",
    "        if len(vc)<=len(opt)*1.1:\n",
    "            count_success=count_success+1\n",
    "    print('Score: %.3f' % (count_success / NUM_EVAL_SIMS))\n",
    "    scores.append(count_success / NUM_EVAL_SIMS)\n",
    "    \n",
    "\n",
    "plt.plot(scores)\n",
    "plt.ylabel('Performance')\n",
    "plt.xlabel('Self Play / Training Iterations')\n",
    "plt.title('Percentage of Good AlphaMinVertex Approximations during Training')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
